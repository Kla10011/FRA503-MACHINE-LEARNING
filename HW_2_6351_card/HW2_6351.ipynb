{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยชุดข้อมูลนี้ต้องการให้เราทำนายว่าผู้ใช้งาน credit_card จะมีแนวโน้มว่าจะยกเลิก หรือ จะใช้งาน credit_card ต่อไปโดยวิเคราะห์จาก feature ที่มี\n",
    "จากข้อมูลที่ได้มามี feature ทั้งหมด 23 feature และมี sample ทั้งหมด 10127 คน จากคำแนะนำของชุดข้อมูลได้ทำการลบ 2 feature สุดท้ายออก<br>\n",
    "แยก feature Attrition_Flag ออกมาเก็บในตัวแปล df_y เหลือชุดข้อมูลในการวิเคราะห์ทั้งหมด 20 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "df = pd.read_csv('credit_card_churn.csv',sep=',')\n",
    "df.columns = [\"CLIENTNUM\",\"Attrition_Flag\",\"Customer_Age\",\"Gender\",\"Dependent_count\",\"Education_Level\",\"Marital_Status\",\"Income_Category\",\"Card_Category\",\"Months_on_book\",\"Total_Relationship_Count\",\"Months_Inactive_12_mon\",\"Contacts_Count_12_mon\",\"Credit_Limit\",\"Total_Revolving_Bal\",\"Avg_Open_To_Buy\",\"Total_Amt_Chng_Q4_Q1\",\"Total_Trans_Amt\",\"Total_Trans_Ct\",\"Total_Ct_Chng_Q4_Q1\",\"Avg_Utilization_Ratio\",\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"]\n",
    "df_y = df[\"Attrition_Flag\"]\n",
    "df = df.drop([\"Attrition_Flag\",\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\",\"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"],axis = 1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยชุดข้อมูลของคนที่ใช้ Credit card อยู่ในปัจจุบันมีจำนวน 8500 คน และ ยกเลิก Credit card มีจำนวน 1627 คน<br>\n",
    "จากการ check ข้อมูลไม่มี missing value ในชุดข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y.value_counts())\n",
    "print(\"\")\n",
    "# ดู missing valus\n",
    "print(df.isnull().sum())\n",
    "print(df.shape)\n",
    "# code handmake\n",
    "# for i in range(0,len(df.columns)):\n",
    "#     print(df.columns[i] +\"\\t\\t\"+ str(df[str(df.columns[i])].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot,df_y,test_size = 0.25,random_state = 25)\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"X_train : \" +str(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree = DecisionTreeClassifier(criterion='entropy',)\n",
    "model_DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_DecisionTree.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_DecisionTree.predict(X_train)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "# predict model test\n",
    "y_pred = model_DecisionTree.predict(X_test)\n",
    "# predict model train\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RandomForest = RandomForestClassifier(n_estimators=100,criterion='entropy')\n",
    "model_RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_RandomForest.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_train)\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RandomForest = RandomForestClassifier(n_estimators=100,criterion='entropy',max_depth=10)\n",
    "model_RandomForest \n",
    "# train model\n",
    "\n",
    "model_RandomForest.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_train)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model test\n",
    "y_pred = model_RandomForest.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_Nearest_Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import machine learning library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict model train\n",
    "y_pred = model_knn.predict(X_train)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model test\n",
    "y_pred = model_knn.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แยกชุดข้อมูลประเภท numeric and Categorical และเพื่ม y ที่เปลี่ยนข้อมูลจาก[\"Existing Customer\",\"Attrited Customer\"] เป็น [1,0] เข้าไปในข้อมูลทั้ง 2 ประเภท<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_y = pd.get_dummies(df_y)\n",
    "df_y = df_y.replace([\"Existing Customer\",\"Attrited Customer\"],[1,0])\n",
    "print(df_y.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class = df.select_dtypes(object)\n",
    "df_numer = df.drop(df_class.columns,axis= 1)\n",
    "\n",
    "# เพื่ม y \n",
    "df_class = df_class.join([df_y])\n",
    "df_numer = df_numer.join([df_y])\n",
    "print(\"numeric : \"+str(df_numer.shape))\n",
    "print(\"class : \"+str(df_class.shape))\n",
    "# df_numer = df.drop(df_class.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot ข้อมูลประเภท Categorical ในอยู่ในแบบใน numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.get_dummies(df_class)\n",
    "print(len(df_class.shape))\n",
    "# print(len(df_class.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot heatmap numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = df_numer.corr()\n",
    "# mask = np.array(corr)\n",
    "# # print(corr)\n",
    "# mask[np.tril_indices_from(mask)] = False     \n",
    "# fig,ax = plt.subplots()\n",
    "# fig.set_size_inches(10,5)\n",
    "# sns.heatmap(corr,mask= mask,vmax =1,vmin = -1,annot= True,cmap= 'coolwarm')\n",
    "Image(url=\"pic/heatmap numeric.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot heatmap Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = df_class.corr()\n",
    "# mask = np.array(corr)\n",
    "# # print(corr)\n",
    "# mask[np.tril_indices_from(mask)] = False     \n",
    "# fig,ax = plt.subplots()\n",
    "# fig.set_size_inches(10,5)\n",
    "# sns.heatmap(corr,mask= mask,vmax =1,vmin =-1,annot= True,cmap= 'coolwarm')\n",
    "Image(url=\"pic/heatmap classification.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_class,hue=\"Attrition_Flag\")\n",
    "Image(url=\"pic/pairplot classification.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairplot Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_numer,hue=\"Attrition_Flag\")\n",
    "Image(url=\"pic/pairplot numeric.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"pic/pairplot highlight.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการ pairplot ข้อมูลประเภท numeric มาว่ามีช่วงที่มีการแบ่งกลุ่มอย่างชัดเจนในช่วงสีแดง และสีฟ้า"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ผมจึงได้เลือก feature ในข้อมูลประเภท numeric ดังนี้\n",
    "* Credit_Limit \n",
    "* Total_Revolving_Bal\n",
    "* Avg_Open_To_Buy\n",
    "* Total_Amt_Chng_Q4_Q1\n",
    "* Total_Trans_Amt\n",
    "* Total_Trans_Ct\n",
    "* Total_Ct_Chng_Q4_Q1\n",
    "* Avg_Utilization_Ratio\n",
    "* Attrition_Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numer = df_numer.drop([\n",
    "    'CLIENTNUM', \n",
    "    'Customer_Age', \n",
    "    'Dependent_count', \n",
    "    'Months_on_book',\n",
    "    'Total_Relationship_Count', \n",
    "    'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon'],axis = 1)\n",
    "print(df_numer.shape)\n",
    "print(df_numer.columns)\n",
    "print(str(df_numer.columns[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"pic/heatmap highlight.png\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการทำ heatmap ข้อมูลประเภท Categorical พบว่าข้อมูลช่วงสีแดงเป็นข้อมูลที่มีความสัมพันธ์กัน"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ผมจึงได้เลือกใช้ feature ประเภท classificaltion ดังนี้\n",
    "* Gender\n",
    "* Income_Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class = pd.get_dummies(df[[\"Gender\",\"Income_Category\"]])\n",
    "print(\"df_class : \"+str(df_class.shape))\n",
    "\n",
    "df_full = df_numer.join([df_class])\n",
    "df_full = df_full.drop(\"Attrition_Flag\",axis=1)\n",
    "print(df_full.shape)\n",
    "print(df_full.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_full,df_y,test_size = 0.25,random_state = 25)\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"X_train : \" +str(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_DecisionTree = DecisionTreeClassifier(criterion='entropy',)\n",
    "model_DecisionTree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_DecisionTree.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_DecisionTree.predict(X_train)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "# predict model test\n",
    "y_pred = model_DecisionTree.predict(X_test)\n",
    "# predict model train\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RandomForest = RandomForestClassifier(n_estimators=100,criterion='entropy',max_depth=10)\n",
    "model_RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model_RandomForest.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_train)\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ยัง overfining อยู่ ใช้ grid_serarch ในการปรับ parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\"n_estimators\":[100,150,200],\"max_depth\":[10]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best params : {}'.format(grid_search.best_params_))\n",
    "print('Accuracy of trainning set:{:.2f}'.format(grid_search.score(X_train, y_train)))\n",
    "print('Accuracy of testing set:{:.2f}'.format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RandomForest = RandomForestClassifier(n_estimators=200,criterion='entropy',max_depth=10)\n",
    "model_RandomForest \n",
    "# train model\n",
    "\n",
    "model_RandomForest.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_RandomForest.predict(X_train)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model test\n",
    "y_pred = model_RandomForest.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_Nearest_Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import machine learning library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn = knn.fit(X_train, y_train)\n",
    "print('Accuracy of trainning set:{:.2f}'.format(model_knn.score(X_train, y_train)))\n",
    "print('Accuracy of testing set:{:.2f}'.format(model_knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_knn = knn.fit(X_train, y_train)\n",
    "# predict model train\n",
    "y_pred = model_knn.predict(X_train)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "# predict model test\n",
    "y_pred = model_knn.predict(X_test)\n",
    "# Classification report\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929163599431c7b3e753eb9c75a6800fa8c5c72fb3910ee126ea89c879162a29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
