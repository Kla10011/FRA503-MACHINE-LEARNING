{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ผู้ทำ</b>\n",
    "- นายจรัญวัฒน์ บัวศรี 63340500005\n",
    "- นายธนกฤต เมืองสุวรรณ 63340500020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>จุดประสงค์</b><br>\n",
    "ในการบ้านนี้ ผู้จัดทำจะต้องทำการวิเคราะห์หาผู้ที่จะยังคงใช้บัตรและผู้ที่จะยกเลิกการใช้บัตรเครดิต จากข้อมูลของผู้ใช้บัตรว่าบุคคลไหนจะมีแนวโน้มยกเลิกบัตรเครดิต โดยใช้ข้อมูลจาก credit_card_churn ในการทำนาย โดยสิ่งที่ต้องทำคือทำนายว่าลูกค้าแบบไหนที่จะยกเลิกการใช้บัตรเครดิตเพื่อให้ความสนใจกับลูกค้าประเภทนั้น และให้ความสำคัญในกาหาเหตุผลที่ลูกค้าจะยกเลิกบัตรเครดิต"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credit_card_churn.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\FRA503-MACHINE-LEARNING\\HW_2_6351_card\\example_from_myfriend\\HW2_6305_6320.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FRA503-MACHINE-LEARNING/HW_2_6351_card/example_from_myfriend/HW2_6305_6320.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mcredit_card_churn.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m     f,\n\u001b[0;32m   1219\u001b[0m     mode,\n\u001b[0;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1226\u001b[0m )\n\u001b[0;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Kla\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credit_card_churn.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit_card_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจสอบ dataset ว่ามีข้มูลอะไรบ้าง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variables :\n",
    "1. CLIENTNUM\n",
    "2. Customer_Age\n",
    "3. Gender\n",
    "4. Dependent_count\n",
    "5. Education_Level\n",
    "6. Marital_Status\n",
    "7. Income_Category\n",
    "8. Card_Category\n",
    "9. Months_on_book\n",
    "10. Total_Realationship_Count\n",
    "11. Months_Inactive_12_mon\n",
    "12. Contacts_Count_12_mon\n",
    "13. Credit_Limit\n",
    "14. Total_Revolving_Bal\n",
    "15. Avg_Open_To_Buy\n",
    "16. Total_Amt_Chng_Q4_Q1\n",
    "17. Total_Trans_Amt\n",
    "18. Total_Trans_Ct\n",
    "19. Total_Ct_Chng_Q4_Q1\n",
    "20. Avg_Utilization_Ratio\n",
    "21. Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\n",
    "22. Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\n",
    "### Output variable :\n",
    "22. Attrition_Flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"Attrition_Flag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns ที่เป็น ชื่อ และ data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"CLIENTNUM\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรวจสอบชนิดของข้อมูลแต่ละ column และค่า null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใช้ pairplot เพื่อดู pattern ของ class เมื่อนำ feature แต่ละตัวมาเะปรียบเทียบกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"Attrition_Flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### แยกชนิดของข้อมูลเป็น continues value, discrete value และ categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = list(df.select_dtypes('float64').columns) + list(df.select_dtypes('int64').columns)\n",
    "categorical_columns = list(df.select_dtypes('object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\"Dependent_count\", \"Total_Relationship_Count\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\"]\n",
    "contineous_columns = [e for e in numerical_columns if e not in discrete_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contineous_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = df[contineous_columns]\n",
    "compare_df = pd.concat((compare_df,df[\"Attrition_Flag\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiztion เพื่อดูขอบเขตและ density ของแต่ละ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(compare_df,hue=\"Attrition_Flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(compare_df,hue=\"Attrition_Flag\", kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการใช้ pairplot จะพบว่า feature บางตัวเมื่อนำมาเปรียบเทียบกันก็จะสามารถจัดกลุ่มข้อมูลเดียวกันให้มากระจุกตัวเป็นกลุ่มเดียวกันและจะเห็น density ของข้อมูลแต่ละ class ว่าอยู่ห่างกันยังไงบ้าง โดยเริ่มจากการเปรียบเทียบ continuous value เทียบกับ continuous value เช่น\n",
    "- custom_age เทียบกับ total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct และ total_change_ct\n",
    "- mounts_on_book เทียบกับ total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct และ total_change_ct\n",
    "- credit_limit เทียบกับ total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct และ total_change_ct\n",
    "- total_revenue_bal เทียบกับ total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct และ total_change_ct\n",
    "- avg_open_to_buy เทียบกับ total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct และ total_change_ct\n",
    "- total_amt_change_Q4_Q1 เทียบกับ total_ct_change_Q4_Q1, total_change_ct และ total_amt_change_Q4_Q1\n",
    "- total_trans_amt เทียบกับ total_ct_change_Q4_Q1, total_trans_ct, total_amt_change_Q4_Q1, avg_open_to_buy, total_revenue_bal และ credit_limit\n",
    "\n",
    "ซึ่งจะเห็นว่า feature ที่สามารถแบ่งกลุ่มข้อมูลที่ค่อนข้างชัดเจนจะได้แก่ total_amt_change_Q4_Q1, total_amt_change_Q4_Q1, total_trans_amt, total_trans_ct, total_ct_change_Q4_Q1 และ avg_open_to_buy\n",
    "ถึงแม้ว่าข้อมูลมากระจุกตัวเป็นกลุ่มก้อน แต่ข้อมูลไม่สามารถถูกแบ่งได้ด้วยการใช้เส้นแบ่งธรรมดาเนื่องจากข้อมูลส่วนใหญ่มีการซ้อนทับกันซึ่งอาจจะค้องใช้ classifier ที่สามารถเปลี่ยน hyperplane ของการแสดงผลข้อมูลในการวิเคราะห์<br>\n",
    "เราจึงตั้งสมมติฐานกับข้อมูลที่ได้ดังนี้\n",
    "- คนที่ยกเลิกบัตรเครดิตมักจะมีข้อมูล total_amt_change_Q4_Q1 น้อยกว่า 1\n",
    "- คนที่ยกเลิกบัตรเครดิตมักจะมีข้อมูล total_ct_change_Q4_Q1 น้อยกว่า 2\n",
    "- คนที่ยกเลิกบัตรเครดิตมักจะมีข้อมูล total_trans_amt น้อยกว่า 15000\n",
    "- คนที่ยกเลิกบัตรเครดิตมักจะมีข้อมูล total_trans_ct น้อยกว่า 100\n",
    "- ต้องใช้ model หรือแปลงข้อมูลให้อยู่ในปริภูมิที่ที่ทำให้สามารถแยก classs ได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### เปรียบเทียบข้อมูล categorical และ continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูลอายุเทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Customer_Age\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Customer_Age\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Customer_Age\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Customer_Age\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Customer_Age\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Customer_Age\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Customer_Age\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Customer_Age\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Customer_Age\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Customer_Age\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Customer_Age กับ categorical ได้ผลดังนี้\n",
    "- จากกราฟพบว่าการกระจายตัวของอายุทั้งเพศชายและเพศหญิงมีลักษณะเหมือนกัน ซึ่งแสดงให้เห็นว่าไม่ว่าเพศไหนอายุเท่าไรไม่สามารถบอกได้ว่าจะถือหรือยกเลิกบัตร\n",
    "- จากกราฟพบว่าการกระจายตัวของการศึกษามีลักษณะเหมือนกัน ทำให้ไม่ส่าผู้นั้นจะจบการศึกษามาระดับไหน ก็ไม่สามารถบอกได้ว่าเขาจะถือหรือยกเลิกบัตรเครดิต\n",
    "- จากกราฟ boxplot พบว่าการกระจายตัวของอายุในแต่ละการศึกษามีลักษณะเหมือนกัน และจะเห็นได้ว่าอายุของคนที่จบการศึกษาในแต่ระดับไม่สามารถแยก class ได้อย่างชัดเจน\n",
    "- จากกราฟ boxplot พบว่าการกระจายตัวของอายุในแต่ละช่วงเงินเดือนมีลักษณะเหมือนกัน และบว่าการเปรียบเทียบอายุกับเงินเดือนไม่สามารถบ่งบอกได้ถึงแนวโน้มการยกเลิกบัตรเครดิต\n",
    "- จากการฟพบว่าถึงแม้บัตรประเภท platinum จะมีจำนวนผู้ที่ถือน้อยที่สุดแต่เมื่อนำมาพิจารณาร่วมกับอายุพบว่าผผู้ที่มีอายุมากที่ถือบัตร Platinum มักมีแนวโน้มจะยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Credit limit เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Credit_Limit\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Credit_Limit\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Credit_Limit\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Credit_Limit\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Credit_Limit\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Credit_Limit\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Credit_Limit\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Credit_Limit\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Credit_Limit\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Credit_Limit\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ credit limit กับ categorical ได้ผลดังนี้\n",
    "- จากการฟจะพบว่าข้อมูล credit limit ของแต่ละเพศมีการเบ้ขวา ซึ่งกราฟแสดงให้เห็นว่าเพศชายมี credit limit ที่สูงกว่าเพศหญิงได้ชัดแต่ข้อมูลกราฟการกระจาตัวของผู้ที่ถือบัตรเครดิตและยกเลิกบัตรเครดิตมีความเหมือนกันในแต่ละเพศทำให้ไม่สามารถประเภทได้อย่างชัดเจน\n",
    "- จากการฟจะพบว่าข้อมูล credit limit ของแต่ละระดับการศึกษาถ้ามีค่ามากก็จะมีแนวโน้มที่คนจะถือบัตรเครดิต แต่กราฟการกระจายตัวมีความใกล้เคียงกันทำให้ไม่สามารถแยก class  ได้อย่างชัดเจน\n",
    "- จากการฟจะพบว่าข้อมูล credit limit ของแต่ละสถานะการแต่งงาน พบว่าการกระจายตัวมีความเหมือนกัน จึงสรุปได้ว่าแต่ละสถานะทั้งผู้ที่ถือบัตรและไม่ถือบัตรก็จะมี credits limit ที่ไม่แตกต่างกัน\n",
    "- จากการฟพบว่าคนที่มีเงินเดือนน้อยกว่า 40K มีจำนวนมากที่สุดแต่จากการฟจะเห็นว่าคนกลุ่มนี้มีค่า credit limit ที่ใกล้เคียงกัน โดยแนวโน้มคนที่ใช้บัตรมันจะมีค่าเฉลี่ย credit limit สูงกว่าคนที่ยกเลิกบัตรในแต่ละ class\n",
    "- จากการฟจะพบว่าข้อมูลประเภทของบัตรที่ถูกถือมากที่สุดคือประเภท Blue จากนั้นจึงนำไปหา distribution ของบัตรแต่ละประเภทพบว่า บัตรประเภท Blue Gold Silver มีลักษณะการกระจายตัวใกล้เคียงกันของทั้ง 2 class แต่สำหรับการ์ดประเภท Platinum จะเห็นได้ว่าผู้ที่ถือบัตรจะมีแนวโน้มที่ credits limit สูงกว่าของผู้ที่ยกเลิกบัตรอย่างชัดเจนถึงแม้ว่าจะมีจำนวนผู้ถือบัตรน้อยที่สุด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Avg_Open_To_Buy เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Open_To_Buy\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Avg_Open_To_Buy กับ categorical ได้ผลดังนี้\n",
    "- จากากราฟพบว่าบุคคลที่มีเงินเดือนต่ำกว่า 80K จะมีค่า Avg_Open_To_buy ที่ต่ำกว่าบุคลที่มีเงินเดือนแบบอื่นๆและมีแนวโน้มที่จะยกเลิกบัตรเครดิตมากว่าฐานเงินเดือนอื่นๆเมื่อพิจารณาจากค่าเฉลี่ยและที่บุคคลที่ทีเงินเดือนมากกว่า 80K จะมีแนวโน้มที่คนจะใช้บัตรเครดิตมากว่ายกเลิกแม้ว่าจะไม่สามารถแยกได้อย่างชัดเจน\n",
    "- จากกราฟพบว่าสถานะการแต่งงานของผู้ที่ถือบัตรและยกเลิกบัตรมีการกระจายตัใกล้เคียงกันเมื่อพิจารณาจาก Avg_Open_To_Buy ซึ่งไม่สามารถแยก class ได้ชัดเจน ซึ่งสามารถตีความข้อมูลได้คือ Avg_Open_To_Buy ของสถานะแต่ละแบบไม่สามารถแยก class ได้\n",
    "- จากกราฟพบว่าในแต่ละระดับการศึกษา ผู้ที่ถือบัตรและยกเลิกบัตรมีการกระจายตัวใกล้เคียงกันเมื่อพิจารณาจาก Avg_Open_To_Buy ทำให้บอกได้ว่า Avg_Open_To_buy ในแต่ระดับไม่สามารถบอกได้ถึงแนวโน้มของผู้ถือบัตรและยกเลิกบัตร\n",
    "- จากกราฟพบว่าจำนวนผู้ถือบัตรและยกเลิกบัตรของทั้ง 2 เพศมีจำนวนใกล้เคียงกัน แต่เมื่อตรวจสอบจาก boxplot จะพบว่าผู้หญิงจะมี Avg_Open_To_Buy ต่ำกว่าผู้ชายแต่ไม่สามารถแยกความแตกต่างระหว่าง class เนื่องจาก Avg_Open_To_buy ของแต่ละเพศทั้งทั้งผู้ถือบัตรและยกเลิกบัตร\n",
    "- จากกราฟพบว่าประเภทบัตรเทียบกับ Avg_Open_To_Buy บัตรอื่นๆในที่ไม่ใช่ Platimum ขะพบว่าจะแยกคนที่ใช้บัตรกับยกเลิกบัตรไม่ชัดเจน แต่ในประเภทบัตร platinum จะเห็นได้ว่าผู้ที่มี Avg_Open_To_Buy ต่ำจะมีแนวโน้มที่ยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Total_Amt_Chng_Q4_Q1 เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Amt_Chng_Q4_Q1\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Amt_change_Q4_Q1 กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิงมีการกระจายตัวไม่แตกต่างกัน และโดยคนที่ใช้บัตรเครดิตจะมีค่าเฉลี่ย Total_Amt_change_Q4_Q1 สูงกว่าคนที่ใช้ยกเลิกเครดิต จึงสรุปได้ว่าคนที่มี Total_Amt_change_Q4_Q1 สูงจะมีแนวโน้มใช้บัตรเครกิตไม่ว่าจะเพศไหนก็ตามถึงแม้ว่าแนวโน้มจะไม่ชัดเจน\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าในแต่ละระดับการศึกษาคนที่มี Total_Amt_change_Q4_Q1 สูงจะมีแนวโน้มที่ใช้บัตรมากกว่าถึงแม้แนวโน้มจะไม่ชัดเจน\n",
    "- เมื่อเปรียบเทียบกับสถานะการแต่งงาน พบว่าในแต่ละสถานะมีการกระจายตัวคล้ายกันและพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Amt_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Amt_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตรโดยสถานะการแต่งงานไม่ส่งผลต่อการใช้บัตร\n",
    "- เมื่อเปรียบเทียบกับเงินเดือนพบว่าการกระจายตัวของแต่ละเงินเดือนมีลักษณะเหมือนกันและพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Amt_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Amt_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตรโดยเงินเดือนไม่ส่งผลต่อการใช้ขัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าการกระจายตัวของแต่ละประเภทบัตรมีลักษณะเหมือนกัน และพบว่าค่า Total_Amt_change_Q4_Q1 ไม่สามารถแยกคนที่ใช้กับยกเลิกบัตรได้อย่างชัดเจนเมื่อนำมาใช้คู่กับประเภทบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Total_Ct_Chng_Q4_Q1 เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Ct_Chng_Q4_Q1\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Ct_Change_Q4_Q1 กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิงมีการกระจายตัวไม่แตกต่างกัน และโดยคนที่ใช้บัตรเครดิตจะมีค่าเฉลี่ย Total_Ct_Change_Q4_Q1 สูงกว่าคนที่ใช้ยกเลิกเครดิต จึงสรุปได้ว่าคนที่มี Total_Ct_Change_Q4_Q1 สูงจะมีแนวโน้มใช้บัตรเครกิตไม่ว่าจะเพศไหนก็ตาม\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าในแต่ละระดับการศึกษาคนที่มี Total_Ct_Change_Q4_Q1 สูงจะมีแนวโน้มที่ใช้บัตรมากกว่า\n",
    "- เมื่อเปรียบเทียบกับสถานะการแต่งงาน พบว่าในแต่ละสถานะมีการกระจายตัวคล้ายกันและพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Ct_Change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Ct_Change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตรโดยสถานะการแต่งงานไม่ส่งผลต่อการใช้บัตร\n",
    "- เมื่อเปรียบเทียบกับเงินเดือนพบว่าการกระจายตัวของแต่ละเงินเดือนมีลักษณะเหมือนกันและพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Ct_Change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Ct_Change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตรโดยเงินเดือนไม่ส่งผลต่อการใช้ขัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าการกระจายตัวของแต่ละประเภทบัตรมีลักษณะเหมือนกัน และพบว่าค่าเฉลี่ย Total_Ct_Change_Q4_Q1 ของคนใช้บัตรจะสูงกว่าคนยกเลิกบัตรไม่ว่าจะใช้บัตรประเ๓ทไหนก็ตาม"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Avg_Utilization_Ratio เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Avg_Utilization_Ratio\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Avg_utilization_Ratio กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิง พบว่าเพศหญิงขะมีช่วงและค่าเฉลี่ยของ และโดยคนที่ใช้บัตรเครดิตจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าเพศชายและคนใช้บัตรจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าคนที่ยกเลิกบัตรในทุกเพศ จึงสรุปได้ว่าคนที่มี Avg_utilization_Ratio สูงจะมีแนวโน้มใช้บัตรเครกิตไม่ว่าจะเพศไหนก็ตาม\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าการกระจายตัวของแต่ละระดับจะมีลักษณะเดียวกันและในแต่ละระดับการศึกษาคนที่มี Avg_utilization_Ratio สูงจะมีแนวโน้มที่ใช้บัตรมากกว่า\n",
    "- เมื่อเปรียบเทียบกับสถานะการแต่งงาน พบว่าในแต่ละสถานะมีการกระจายตัวคล้ายกันและพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าคนที่ยกเลิกบัตรโดยสถานะการแต่งงานไม่ส่งผลต่อการใช้บัตร\n",
    "- เมื่อเปรียบเทียบกับเงินเดือน พบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าคนที่ยกเลิกบัตร และสรุปได้ว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Avg_utilization_Ratio สูงกว่าคนที่ยกเลิกบัตรโดยเงินเดือนไม่ส่งผลต่อการใช้ขัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าประเภทบัตรที่ไม่ใช่ platinum จะไม่สามารถแยกคนใช้และคนยกเลิกบัตรเมื่อเทียบกับ Avg_utilization_Ratio และจากบัตรทุกประเภทค่าเฉลี่ย Avg_utilization_Ratio ของคนใช้บัตรจะสูงกว่าคนยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Months_on_book เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_on_book\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_on_book\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_on_book\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_on_book\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_on_book\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_on_book\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_on_book\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_on_book\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_on_book\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_on_book\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Months_on_book กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิง พบว่าเพศทั้งสองมีลักษณะการกระจายตัวเหมือนกันและไม่สามารถแยกคนที่ใช้บัตรและยกเลิกบัตรได้\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าการกระจายตัวของแต่ละระดับจะมีลักษณะคล้ายกันและในแต่ละระดับการศึกษาคนที่มีค่าเฉี่ย Months_on_book ของคนที่ใช้บัตรและยกเลิกบัตรมีค่าไม่ต่างกัน\n",
    "- เมื่อเปรียบเทียบสถานะการแต่งงาน พบว่าการกระจายตัวของแต่ละสถานะจะมีลักษณะคล้ายกันและในแต่ละสถานะคนที่มีค่าเฉี่ย Months_on_book ของคนที่ใช้บัตรและยกเลิกบัตรมีค่าไม่ต่างกัน\n",
    "- เมื่อเปรียบเทียบกับเงินเดือน พบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Months_on_book ไม่ต่างจากคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าบัตรแต่ละประเภทมีการกระจายตัวแบบ normal distribution โดยบัตร Gold คนที่ใช้บัตรจะมีค่าเฉลี่ย Months_on_book สูงกว่าคนที่ยกเลิกบัตร และบัตร Platinum คนที่ใช้บัตรจะมีค่าเฉลี่ย Months_on_book ต่ำกว่าคนที่ยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Total_Revolving_Bal เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Revolving_Bal\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Revolving_Bal\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Revolving_Bal\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Revolving_Bal\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Revolving_Bal\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Revolving_Bal\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Revolving_Bal\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Revolving_Bal\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Revolving_Bal\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Revolving_Bal\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Revolving_Bal กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิง พบว่าเพศทั้งสองมีลักษณะการกระจายตัวเหมือนกันและคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Revolving_Bal สูงกว่าคนที่ยกเลิกบัตรอย่างชัดเจน\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าการกระจายตัวของแต่ละระดับจะมีลักษณะเหมือนกันและในแต่ละระดับการศึกษาคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Revolving_Bal สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบสถานะการแต่งงาน พบว่าการกระจายตัวของแต่ละสถานะจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Revolving_Bal สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบเงินเดือน พบว่าการกระจายตัวของแต่เงินเดือนจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Revolving_Bal สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าผู้ที่ใช้บัตรจะจะมีค่าเฉลี่ย Total_Revolving_Bal สูงกว่าคนที่ยกเลิกบัตร โดยจะสามารถแยกได้อย่างชัดเจนเมื่อเป็นบัตร platinum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Total_Trans_Amt เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Amt\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Amt\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Amt\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Amt\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Amt\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Amt\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Amt\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Amt\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Amt\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Amt\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Trans_Amt กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิง พบว่าเพศชายมีการกระจายตัวของคนที่ใช้และยกเลิกบัตรใกล้เคียงกันแต่ในเพศหญิงพบว่าผู้หญิงที่ใช้บัตรจะมีค่าเฉลี่ย Total_Trans_Amt สูงกว่าผู้หญิงที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าการกระจายตัวของแต่ละระดับจะมีลักษณะเหมือนกันและในแต่ละระดับการศึกษาคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Amt สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบสถานะการแต่งงาน พบว่าการกระจายตัวของแต่ละสถานะจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Amt สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบเงินเดือน พบว่าการกระจายตัวของแต่เงินเดือนจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Amt สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าในบัตร Blue Gold และ Platinum ผู้ที่ใช้บัตรจะจะมีค่าเฉลี่ย Total_Trans_Amt สูงกว่าคนที่ยกเลิกบัตร โดยจะสามารถแยกได้อย่างชัดเจนเมื่อเป็นบัตร platinum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อมูล Total_Trans_Ct เทียบกับ categorical ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Gender\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Ct\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Ct\", y=\"Gender\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Education_Level\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Ct\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Ct\", y=\"Education_Level\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Marital_Status\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Ct\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Ct\", y=\"Marital_Status\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Income_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Ct\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Ct\", y=\"Income_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Card_Category\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Trans_Ct\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Trans_Ct\", y=\"Card_Category\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Trans_Ct กับ categorical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับเพศผู้ใช้งานทั้งชายและหญิง พบว่าเพศชายมีการกระจายตัวของ Total_Trans_Ct มากกว่าเพศหญิง และทั้งสองเพศคนที่ใช้บัตรจะมีค่าเฉลี่ย Total_Trans_Ct สูงกว่าคนที่ไม่ใช้บัตร\n",
    "- เมื่อเปรียบเทียบกับระดับการศึกษา พบว่าการกระจายตัวของแต่ละระดับจะมีลักษณะเหมือนกันยกเว้น Married และในแต่ละระดับการศึกษาคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Ct สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบสถานะการแต่งงาน พบว่าการกระจายตัวของแต่ละสถานะจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Ct สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบเงินเดือน พบว่าการกระจายตัวของแต่เงินเดือนจะมีลักษณะคล้ายกันและคนที่ใช้บัตรมีแนวโน้มค่าเฉลี่ย Total_Trans_Ct สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับประเภทบัตรพบว่าคนที่ใช้บัตรจะมีค่า Total_Trans_Ct สูงกว่าคนที่ยกเลิกบัตร โดยเฉพาะบัตรประเภท Platinum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### เปรียบเทียบข้อมูล categorical และ discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### เปรียบเทียบ Dependent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Dependent_count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Dependent_count\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Dependent_count\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Dependent_count กับ numerical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับอายุพบว่าเมื่อนำ Dependent_count ค่าต่างๆจะมีการกระจายตัวของอายุเป็น normal distribution ทั้งของคนที่ใช้บัตรและยกเลิกบัตรเครดิต\n",
    "- เมื่อเปรียบเทียบกับcredits_limit พบว่าการกระจายตัวของแต่ละ Dependent_count จะมีลักษณะเหมือนและในขณที่ค่า Dependent_count 1-5 แสดงให้เห็นว่าผู่ที่ยกเลิกบัตรเครดิตมีแนวโน้มค่าเฉลี่ยของของ credit_limits ที่มากกว่าคนที่ใช้บัตร ยกเว้นค่า Dependent_count 0 ซึ่งอาจจะทำให้ค่าบางค่าใน freature ไม่ได้ใช้ weight เดียวกันกับค่าอื่น\n",
    "- เมื่อเปรียบเทียบกับ Avg_Open_To_Buy พบว่ามีกระจายตัวใกล้เคียงกันและค่าเฉลี่ยของ Avg_Open_To_Buy มีค่าใกล้เคียงกันทั้งคนที่ใช้บัตรและยกเลิกบัตรทำให้ไม่สามารถแยกได้อย่างชัดเจน\n",
    "- เมื่อเปรียบเทียบ Total_Amt_change_Q4_Q1 พบว่ามีการกระจายตัวใกล้เคียงกันในทุกๆค่าของ Dependent_count และกระจายตัวแบบ normal distribution\n",
    "- เมื่อเปรียบเทียบ Total_ct_change_Q4_Q1 พบว่ามีการกระจายตัวของคนที่ใช้บัตรและยกเลิกบัตรเป็น normal distribution และเมื่อพิจารณาจากฐานนิยมและค่าเฉลี่ยจะสามารถแยกคนที่ใช้บัตรและยกเลิกบัตรได้ค่อนข้างชัดเจน โดยคนที่ใช้บัตรจะมีแนวโน้มค่า Total_ct_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Avg_Utilization_Ratio พบว่าคนที่ใช้บัตรมีแนวโน้มที่ค่าเฉลี่ย Avg_Utilization_Ratio คนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Mount_on_book พบว่าที่ค่า Dependent_count 0-1 คนที่ใช้บัตรจะมีค่าเฉลี่ย Mount_on_book ต่ำกว่าคนที่ยกเลิกบัตร ในขณะที่ Dependent_count 2-5 ไม่สามารถแยกคนใช้บัตรและยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Revolving_Bal พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Revolving_Bal ที่สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Amt พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Amt ที่สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Ct พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Ct ที่สูงกว่าคนที่ยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### เปรียบเทียบ Total_Relationship_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Total_Relationship_Count\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Total_Relationship_Count\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Total_Relationship_Count กับ numerical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับอายุพบว่าเมื่อนำ Total_Relationship_Count ค่าต่างๆจะมีการกระจายตัวของอายุเป็น normal distribution ทั้งของคนที่ใช้บัตรและยกเลิกบัตรเครดิต\n",
    "- เมื่อเปรียบเทียบกับcredits_limit พบว่าการกระจายตัวของแต่ละ Total_Relationship_Count จะมีลักษณะเหมือนและในขณที่ค่า Total_Relationship_Count 1-5 แสดงให้เห็นว่าผู่ที่ใช้บัตรเครดิตมีแนวโน้มค่าเฉลี่ยของของ credit_limits ที่มากกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับ Avg_Open_To_Buy พบว่ามีกระจายตัวใกล้เคียงกันและค่าเฉลี่ยของ Avg_Open_To_Buy มีค่าใกล้เคียงกันทั้งคนที่ใช้บัตรและยกเลิกบัตรทำให้ไม่สามารถแยกได้อย่างชัดเจน\n",
    "- เมื่อเปรียบเทียบ Total_Amt_change_Q4_Q1 พบว่ามีการกระจายตัวใกล้เคียงกันในทุกๆค่าของ Total_Relationship_Count และกระจายตัวแบบ normal distribution\n",
    "- เมื่อเปรียบเทียบ Total_ct_change_Q4_Q1 พบว่ามีการกระจายตัวของคนที่ใช้บัตรและยกเลิกบัตรเป็น normal distribution และเมื่อพิจารณาจากฐานนิยมและค่าเฉลี่ยจะสามารถแยกคนที่ใช้บัตรและยกเลิกบัตรได้ค่อนข้างชัดเจน โดยคนที่ใช้บัตรจะมีแนวโน้มค่า Total_ct_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Avg_Utilization_Ratio พบว่าคนที่ใช้บัตรมีแนวโน้มที่ค่าเฉลี่ย Avg_Utilization_Ratio คนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Mount_on_book พบว่าที่ค่า Total_Relationship_Count ไม่สามารถแยกคนใช้บัตรและยกเลิกบัตรได้อย่างชัดเจนเนื่อจากมีการกระจายตัวและค่าเฉลี่ยเหมือนกันในทุกๆค่าของ Total_Relationship_Count\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Revolving_Bal พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Revolving_Bal ที่สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Amt พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Amt ที่สูงกว่าคนที่ยกเลิกบัตร โดยเฉพาะค่าที่ 1-2 ที่สามารถแยกได้อย่างชัดเจนซึ่เมื่อนำค่า Discrete ไปทำ Onehot encoding ให้ weigth ไม่เท่ากันในแต่ละค่าของ feature อาจได้ผลการทำนายที่ดีขึ้น\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Ct พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Ct ที่สูงกว่าคนที่ยกเลิกบัตร โดยเฉพาะค่าที่ 1-2 ที่สามารถแยกได้อย่างชัดเจนซึ่เมื่อนำค่า Discrete ไปทำ Onehot encoding ให้ weigth ไม่เท่ากันในแต่ละค่าของ feature อาจได้ผลการทำนายที่ดีขึ้น"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### เปรียบเทียบ Months_Inactive_12_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Months_Inactive_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Months_Inactive_12_mon\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Months_inactive_12_mon กับ numerical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับอายุพบว่าเมื่อนำ Months_inactive_12_mon ค่าต่างๆจะมีการกระจายตัวของอายุเป็น normal distribution ทั้งของคนที่ใช้บัตรและยกเลิกบัตรเครดิต และจาก boxplot จะเห็นว่าค่า Months_inactive_12_mon 1-6 คนที่ยกเลิกบัตรจะมีแนวโน้มอายุที่เพิ่มขึ้นและค่า Months_inactive_12_mon 1,3,4,5,6 พบว่าคนที่ยกเลิกบัตรมักจะมีค่าเฉลี่ยอายุที่สูงกว่าคนที่ใช้บัตร\n",
    "- เมื่อเปรียบเทียบกับcredits_limit พบว่าการกระจายตัวของแต่ละ Months_inactive_12_mon จะมีลักษณะเหมือนกันและค่าเฉลี่ยใกล้เคียงกันทั้งของคนที่ใช้บัตรและยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับ Avg_Open_To_Buy พบว่ามีกระจายตัวใกล้เคียงกันและค่าเฉลี่ยของ Avg_Open_To_Buy บางค่าทำให้เราสามารถแยกประเภทคนได้แม้ไม่ชัดเจน\n",
    "- เมื่อเปรียบเทียบ Total_Amt_change_Q4_Q1 พบว่ามีการกระจายตัวใกล้เคียงกันในทุกๆค่าของ Months_inactive_12_mon และกระจายตัวแบบ normal distribution โดยค่า Months_inactive_12_mon 0 มีจำนวนที่น้อยที่สุดแต่จะพบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย Months_inactive_12_mon ที่สูงกว่าคนยกเลิกบัตร โดยค่าอื่นๆใน feature ก็ให้ข้อสังเกตแบบเดียวกัน\n",
    "- เมื่อเปรียบเทียบ Total_ct_change_Q4_Q1 พบว่ามีการกระจายตัวของคนที่ใช้บัตรและยกเลิกบัตรเป็น normal distribution และเมื่อพิจารณาจากฐานนิยมและค่าเฉลี่ยจะสามารถแยกคนที่ใช้บัตรและยกเลิกบัตรได้ค่อนข้างชัดเจน โดยคนที่ใช้บัตรจะมีแนวโน้มค่า Total_ct_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Avg_Utilization_Ratio พบว่าคนที่ใช้บัตรมีแนวโน้มที่ค่าเฉลี่ย Avg_Utilization_Ratio สูงคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Mount_on_book พบว่าที่ค่า Months_inactive_12_mon บางค่าสามารถให้ความแตกระหว่างคนที่ใช้บัตรได้แต่ก็จะเห็นว่าค่ามากสุดของคนที่ใช้บัตรและยกเลิกบัตรก็มีค่าใกล้เคียงกัน\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Revolving_Bal พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Revolving_Bal ที่สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Amt พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Amt ที่สูงกว่าคนที่ยกเลิกบัตร\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Ct พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Ct ที่สูงกว่าคนที่ยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### เปรียบเทียบ Contacts_Count_12_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Customer_Age\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Credit_Limit\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Avg_Open_To_Buy\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Amt_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Ct_Chng_Q4_Q1\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Avg_Utilization_Ratio\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Months_on_book\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Revolving_Bal\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Trans_Amt\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(25,10))\n",
    "sns.countplot(data=df, x=\"Contacts_Count_12_mon\",hue=\"Attrition_Flag\", ax=axs[0])\n",
    "sns.boxplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[1])\n",
    "sns.violinplot(data=df, x=\"Contacts_Count_12_mon\", y=\"Total_Trans_Ct\", hue=\"Attrition_Flag\", ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากกราฟเปรียบเทียบ Contacts_Count_12_mon กับ numerical ได้ผลดังนี้\n",
    "- เมื่อเทียบกับอายุพบว่าเมื่อนำ Contacts_Count_12_mon ค่าต่างๆจะมีการกระจายตัวของอายุเป็น normal distribution ทั้งของคนที่ใช้บัตรและยกเลิกบัตรเครดิต และจากกราฟจะเห็นว่าค่า Contacts_Count_12_mon 0 มื่อเทียบกับอายุจะสามารถบอกได้อย่างชัดเจนว่าคนที่อายูมากและมีค่า Contacts_Count_12_mon เป็น 0 มักจะเป็นคนที่ใช้บัตรรและพบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับ credits_limit พบว่าคนที่ใช้บัตรจะมีค่าเฉลี่ย credit_limits ที่สูงกว่าคนยกเลิกบัตรและพบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับ Avg_Open_To_Buy พบว่ามีกระจายตัวใกล้เคียงกันและค่าเฉลี่ยของ Avg_Open_To_Buy บางค่าทำให้เราสามารถแยกประเภทคนได้แม้ไม่ชัดเจนแต่พบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบ Total_Amt_change_Q4_Q1 บพว่าค่า Contacts_Count_12_mon 2-5 ค่าเฉลี่ย Contacts_Count_12_mon ของคนใช้บัตรจะมีมากกว่าคนที่ไม่ใช้บัตร และพบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบ Total_ct_change_Q4_Q1 พบว่ามีการกระจายตัวของคนที่ใช้บัตรและยกเลิกบัตรเป็น normal distribution โดยคนที่ใช้บัตรจะมีแนวโน้มค่า Total_ct_change_Q4_Q1 สูงกว่าคนที่ยกเลิกบัตร และพบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับค่า Avg_Utilization_Ratio พบว่าคนที่ใช้บัตรมีแนวโน้มที่ค่าเฉลี่ย Avg_Utilization_Ratio สูงกว่าคนที่ยกเลิกบัตร และพบว่าคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับค่า Mount_on_book พบว่าที่ค่าเฉลี่ยและการกระจายตัวของคนใช้บัตรและยกเลิกบัตรไม่ต่างกัน ยกเว้นคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Revolving_Bal พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Revolving_Bal ที่สูงกว่าคนที่ยกเลิกบัตรและคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Amt พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Amt ที่สูงกว่าคนที่ยกเลิกบัตรและคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด\n",
    "- เมื่อเปรียบเทียบกับค่า Total_Trans_Ct พบว่าที่คนที่ใช้บัตรมีแนวโน้มที่ค่า Total_Trans_Ct ที่สูงกว่าคนที่ยกเลิกบัตรและคนที่ค่า Contacts_Count_12_mon เป็น 6 จะเป็นคนที่ยกเลิกบัตรทั้งหมด"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการทำ Data Exploration เราได้เห็นถึงความสัมพันธ์ต่างๆของข้อมูล เราจึงตั้งสมมติฐานว่า feature ที่มีความสำคัญต่อการวิเคราะห์มีดังนี้\n",
    "- Total_Ct_Chng_Q4_Q1\n",
    "- Avg_Utilization_Ratio\n",
    "- Total_Revolving_Bal\n",
    "- Total_Trans_Amt\n",
    "- Total_trans_Ct\n",
    "- Dependent_Count\n",
    "- Total_Relationship_Count\n",
    "- Contacts_count_12_mon\n",
    "- Income_Category\n",
    "- Card_Category\n",
    "\n",
    "หลังจากนั้นเราจะทำการพิสูจน์สมมติฐานของเราโดยใช้ feature selection ทางสถิติและของ sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ก่อนที่จะทำ feature selection ผู้จัดทำจึงทำการตัดข้อมูลที่เป็น outlier เพื่อไม่ให้ข้อมูลเหล่านั้นมาทำให้การทำ feature selection ผิดพลาด โดยวิธีที่เลือกคือวิธี Interquartile Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "คำนวณ upper bound และ lower bound ของข้อมูลที่เป็น continuouse value และตัดข้อมูลที่อยู่นอกเหนือระหว่าง upper bound และ lower bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy()\n",
    "for feature in contineous_columns:\n",
    "    q3, q1 = np.percentile(df[feature], [75, 25])\n",
    "    IQR = q3 - q1\n",
    "    upper_bound = q3 + 1.5 * IQR\n",
    "    lower_bound = q1 - 1.5 * IQR\n",
    "    temp_df = temp_df[~((temp_df[feature] < (q1 - 1.5 * IQR)) | (temp_df[feature] > (q3 + 1.5 * IQR)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "หาจำนวน outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"number of outlier {df.shape[0] - temp_df.shape[0]} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize ข้อมูลใหม่เพื่อดูการกระจายตัวของข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = temp_df[contineous_columns]\n",
    "compare_df = pd.concat((compare_df,temp_df[\"Attrition_Flag\"]),axis=1)\n",
    "sns.pairplot(compare_df,hue=\"Attrition_Flag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยข้อมูลที่ได้หลังจากตัด outlier พบว่าการกระจายตัวข้อมูลบางตัวเปลี่ยนไป เช่น Total_Ct_Chng_Q4_Q1 มีความเป็น normal distribution มากขึ้น จากนั้นเช็กจำนวนของคนที่ใช้บัตรและยกเลิกบัตร"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ดู distribution ของข้อมูล continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[0], kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทำการแก้ไข distribution โดยใช้ binning ทุก 10 เปอร์เซนไทล์"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = temp_df[contineous_columns[0]].quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots()\n",
    "temp_df[contineous_columns[0]].hist(ax=ax, bins=100)\n",
    "for pos in deciles:\n",
    "    handle = plt.axvline(pos, color='r')\n",
    "ax.legend([handle], ['deciles'], fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_xlabel('Credits limit', fontsize=14)\n",
    "ax.set_ylabel('Occurrence', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = pd.qcut(temp_df[contineous_columns[0]], 10, labels=False)\n",
    "sns.displot(data=temp_val)\n",
    "unique, counts = np.unique(temp_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[contineous_columns[0]] = temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[1], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = temp_df[contineous_columns[1]].quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots()\n",
    "temp_df[contineous_columns[1]].hist(ax=ax, bins=100)\n",
    "for pos in deciles:\n",
    "    handle = plt.axvline(pos, color='r')\n",
    "ax.legend([handle], ['deciles'], fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_xlabel('Avg_Open_To_Buy', fontsize=14)\n",
    "ax.set_ylabel('Occurrence', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = pd.qcut(temp_df[contineous_columns[0]], 10, labels=False)\n",
    "sns.displot(data=temp_val)\n",
    "unique, counts = np.unique(temp_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[contineous_columns[1]] = temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[2], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[3], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[4], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = temp_df[contineous_columns[4]].quantile([.1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots()\n",
    "temp_df[contineous_columns[4]].hist(ax=ax, bins=100)\n",
    "for pos in deciles:\n",
    "    handle = plt.axvline(pos, color='r')\n",
    "ax.legend([handle], ['deciles'], fontsize=14)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_xlabel('Avg_Otilization_Ratio', fontsize=14)\n",
    "ax.set_ylabel('Occurrence', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = pd.qcut(temp_df[contineous_columns[4]], 10, labels=False,duplicates= 'drop')\n",
    "sns.displot(data=temp_val)\n",
    "unique, counts = np.unique(temp_val, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[contineous_columns[4]] = temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[5], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[6], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[7], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[8], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=temp_df, x=contineous_columns[9], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[\"Attrition_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = temp_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยการทำ feature selection เราได้เลือกมา 3 วิธีได้แก่ Random forest, chi2 และ PCA เพื่อทำการทดลองหาวิธีทำ feature selection ที่เหาะสมที่สุดสำหรับการทำ feature selection ในข้อมูลชุดนี้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เปลี่ยข้อมูล Discrete ให้เป็น Categorical และทำการ normalize ค่า Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in discrete_columns:\n",
    "    dataset[feature] = dataset[feature].astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dataset.drop(columns=[\"Attrition_Flag\"]))\n",
    "y = np.where(dataset[\"Attrition_Flag\"] == \"Existing Customer\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ใช้ Random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "for feature in contineous_columns:\n",
    "    X[feature] = sc.fit_transform(X[feature].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data,X_test,y_data,y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feat= X_data.columns[(sel.get_support())]\n",
    "len(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการใช้ Random forest ทำ feature selection ได้ผลลัพธ์ feature ที่ตรงกับเราเลือกมา 6 feature ได้แก่ Total_Revolving_Bal, Total_Trans_Amt, Total_Trans_Ct, Total_Ct_Chng_Q4_Q1, Avg_Utilization_Ratio และ Total_Relationship_Count จากนั้นเราสร้างข้อมูลด้วย feature ที่ถูกเลือกเหล่านี้ไปทำการทดลองต่อไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_X_data = X_data[selected_feat]\n",
    "rf_X_test = X_test[selected_feat]\n",
    "rf_y_data = y_data\n",
    "rf_y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dataset.drop(columns=[\"Attrition_Flag\"]))\n",
    "y = np.where(dataset[\"Attrition_Flag\"] == \"Existing Customer\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data,X_test,y_data,y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(chi2, k=13)     #This line creates the selector\n",
    "x_new = selector.fit(X_data,y_data)             #This line fits the selector to the dataset, and select the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = selector.get_support(indices=True)   #all indices are saved in col.\n",
    "X_data.columns[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการใช้ chi2 ทำ feature selection ได้ผลลัพธ์ feature ที่ตรงกับเราเลือกมา 8 feature ได้แก่ Total_Revolving_Bal, Total_Trans_Amt, Total_Trans_Ct, Total_Ct_Chng_Q4_Q1, Avg_Utilization_Ratio, Total_Relationship_Count, Months_Inactive_12_mon  Contacts_Count_12_mon จากนั้นเราสร้างข้อมูลด้วย feature ที่ถูกเลือกเหล่านี้ไปทำการทดลองต่อไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_X_data = X_data[X_data.columns[col]]\n",
    "chi2_X_test = X_test[X_data.columns[col]]\n",
    "chi2_y_data = y_data\n",
    "chi2_y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = len(X_data.columns))           # Create PCA transformer\n",
    "x_pca = pca.fit_transform(X_data)          # Fit and transform PCA transformer to the dataset\n",
    "\n",
    "print(pca.explained_variance_ratio_)  # This show the variance of each component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการดูเปอเซนต์ของจำนวณ compunent axis ที่สามารถแปลงข้อมูลลงไปพบว่าที่ 3 component axis สามารถคลอบคุรมข้อมูลได้มากกว่า 90 % จึงใช้เลือก n_component ใช้เป็น 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "pca_X_data = pca.fit_transform(X_data)\n",
    "pca_X_test = pca.transform(X_test)\n",
    "pca_y_data = y_data\n",
    "pca_y_test = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จากการ visualize ข้อมูล พบว่าประเภทของคนที่ใช้บัตรและไม่ใช้บัตรไม่สามารถแยกได้ด้วยการขีดเส้นแบ่ง แต่อาจจะต้องนำข้อมูลเหล่านั้นไปมองในมุมใหม่หรือสร้าง Hyperplane เพื่อใช้ในการแบ่ง โดย model ที่เลือกมามีดังนี้\n",
    "- Logistic regression โดยนำมาทดสอบกับข้อมูลที่ทำ feature selection ว่าสามารถแบ่งประเภทได้หรือไม่\n",
    "- KNN เนื่องจากข้อมูลที่นำมาอาจจะไม่มี pattern ที่แบ่งแยกได้เป็นกลุ่มก้อนเดียวของ class นั้น จากที่สังเกตจาก pairplot จึงใช้ KNN เพื่อดูว่าข้อมูลตัวนี้อยู่ใกล้กลุ่มก้อนไหน\n",
    "- Random forest ข้อมูลที่นำมาจากการทำเทียบข้อมูล Discrete และ Continuous พบว่าบาง feature จะมีค่าใน feature ที่สามารถใช้แยกประเภทได้มากว่าอันอื่น จึงเลือกใช้ model ที่ค่อยๆแบ่งประเภทจาก feature ไปเรื่อยๆ\n",
    "- SVM เนื่องจากการ visaulize พบว่าไม่สามารถแยกประเภทได้ จึงเลือก SVM มาทำ hyperplane ในการแยกประเภท\n",
    "- Naiev Bayes เนื่องจากการ visaulize พบว่าไม่สามารถแยกประเภทได้ จึงใช้ความน่าจะเป็นมาวิเคราะห์ว่าจะใช้บัตรหรือไม่ใช้บัตร\n",
    "- Deep learning เมื่อต้องการหา pattern ของข้อมูลทั้งสอง class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้าง parameter สำหรับทำ hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grids = [\n",
    "    {\n",
    "        \"alpha\": np.power(10, np.arange(-4, 4, dtype=float)),\n",
    "        \"class_weight\": [{0: 1, 1: 1}, {0: 1, 1: 1.1}, {0: 1, 1: 1.2}, {0: 1, 1: 1.3}, {0: 1, 1: 1.4}, {0: 1, 1: 1.5}, 'balanced']\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SGDclassifier กับข้อมูลที่ใช้ random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "lr = SGDClassifier()\n",
    "\n",
    "gs = GridSearchCV(lr, lr_param_grids, cv=10)\n",
    "gs.fit(rf_X_data, rf_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier(alpha=0.001, class_weight={0: 1, 1: 1.1})\n",
    "lr.fit(rf_X_data, rf_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "cv = cross_val_score(lr,rf_X_data, rf_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(lr,rf_X_test, rf_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(rf_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(rf_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SGDclassifier กับข้อมูลที่ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier()\n",
    "\n",
    "gs = GridSearchCV(lr, lr_param_grids, cv=10)\n",
    "gs.fit(chi2_X_data, chi2_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier(alpha=0.01, class_weight={0: 1, 1: 1.4})\n",
    "lr.fit(chi2_X_data, chi2_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(lr,chi2_X_data, chi2_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(lr,chi2_X_test, chi2_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(chi2_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(chi2_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SGDclassifier กับข้อมูลที่ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier()\n",
    "\n",
    "gs = GridSearchCV(lr, lr_param_grids, cv=10)\n",
    "gs.fit(pca_X_data, pca_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = SGDClassifier(alpha=1, class_weight={0: 1, 1: 1.2})\n",
    "lr.fit(pca_X_data, pca_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(lr,pca_X_data, pca_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(lr,pca_X_test, pca_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(pca_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(pca_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง Logistic Regression โมเดล SGDclassifier กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ SGDclassifier กับข้อมูลที่ใช้ PCA ในการทำ feature selection ให้ค่า recall มากที่สุดอยู่ที่ 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้าง parameter สำหรับทำ hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grids = [\n",
    "    {\n",
    "        \"n_neighbors\": [3, 5, 7, 9, 11, 13],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง knn กับข้อมูลที่ใช้ random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs = GridSearchCV(knn, knn_param_grids, cv=10)\n",
    "gs.fit(rf_X_data, rf_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(rf_X_data, rf_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(knn,rf_X_data, rf_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(knn,rf_X_test, rf_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(rf_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(rf_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง knn กับข้อมูลที่ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs = GridSearchCV(knn, knn_param_grids, cv=10)\n",
    "gs.fit(chi2_X_data, chi2_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(chi2_X_data, chi2_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(knn,chi2_X_data, chi2_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(knn,chi2_X_test, chi2_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = knn.predict(chi2_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(chi2_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง knn กับข้อมูลที่ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gs = GridSearchCV(knn, knn_param_grids, cv=10)\n",
    "gs.fit(pca_X_data, pca_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(pca_X_data, pca_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(knn,pca_X_data, pca_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(knn,pca_X_test, pca_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(pca_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(pca_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred, labels=gs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง KNN กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ KNN กับข้อมูลที่ใช้ chi2 และ PCA ในการทำ feature selection ให้ค่า recall มากที่สุดอยู่ที่ 0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้าง parameter สำหรับทำ hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grids = [\n",
    "    {\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"class_weight\": [\"balanced\", \"balanced_subsample\"] \n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Random forest กับข้อมูลที่ใช้ random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(rf, rf_param_grids, cv=10)\n",
    "gs.fit(rf_X_data, rf_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_leaf_nodes=2,class_weight=\"balanced\", criterion=\"log_loss\")\n",
    "rf.fit(rf_X_data, rf_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(rf,rf_X_data, rf_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(rf,rf_X_test, rf_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(rf_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(rf_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Random forest กับข้อมูลที่ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(rf, rf_param_grids, cv=10)\n",
    "gs.fit(chi2_X_data, chi2_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\", criterion=\"log_loss\")\n",
    "rf.fit(chi2_X_data, chi2_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(rf,chi2_X_data, chi2_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(rf,chi2_X_test, chi2_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(chi2_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(chi2_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Random forest กับข้อมูลที่ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "gs = GridSearchCV(rf, rf_param_grids, cv=10)\n",
    "gs.fit(pca_X_data, pca_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\", criterion=\"log_loss\")\n",
    "rf.fit(pca_X_data, pca_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(rf,pca_X_data, pca_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(rf,pca_X_test, pca_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(pca_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(pca_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred, labels=rf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง Random Forest กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ Random Forest กับข้อมูลที่ใช้ random forest ในการทำ feature selection ให้ค่า recall มากที่สุดอยู่ที่ 0.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_grids = [\n",
    "    {\n",
    "        \"kernel\": [\"rbf\", \"poly\"]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SVM กับข้อมูลที่ใช้ random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "\n",
    "gs = GridSearchCV(clf, svc_param_grids, cv=10, n_jobs=-1)\n",
    "gs.fit(rf_X_data, rf_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(rf_X_data, rf_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,rf_X_data, rf_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,rf_X_test, rf_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(rf_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(rf_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SVM กับข้อมูลที่ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "gs = GridSearchCV(clf, svc_param_grids, cv=10, n_jobs=-1)\n",
    "gs.fit(chi2_X_data, chi2_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(chi2_X_data, chi2_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,chi2_X_data, chi2_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,chi2_X_test, chi2_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(chi2_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(chi2_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง SVM กับข้อมูลที่ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "\n",
    "gs = GridSearchCV(clf, svc_param_grids, cv=10, n_jobs=-1)\n",
    "gs.fit(pca_X_data, pca_y_data)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")\n",
    "clf.fit(pca_X_data, pca_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,pca_X_data, pca_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,pca_X_test, pca_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = gs.predict(pca_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(pca_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง SVM กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ SVM กับข้อมูลที่ใช้ random forest ในการทำ feature selection ให้ค่า recall มากที่สุดอยู่ที่ 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Naive bayes กับข้อมูลที่ใช้ random forest ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(rf_X_data, rf_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,rf_X_data, rf_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,rf_X_test, rf_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = clf.predict(rf_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(rf_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Naive bayes กับข้อมูลที่ใช้ chi2 ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(chi2_X_data, chi2_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,chi2_X_data, chi2_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,chi2_X_test, chi2_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = clf.predict(chi2_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(chi2_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลอง Naive bayes กับข้อมูลที่ใช้ PCA ในการทำ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(pca_X_data, pca_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cross_val_score(clf,pca_X_data, pca_y_data,cv=10,n_jobs=-1)\n",
    "print(f\"train accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "cv = cross_val_score(clf,pca_X_test, pca_y_test,cv=10,n_jobs=-1)\n",
    "print(f\"test accuracy: {np.mean(cv)} +/- {np.std(cv)}\")\n",
    "y_pred = clf.predict(pca_X_data)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(pca_X_test)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง Naive bayes กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ Naive bayes กับข้อมูลที่ใช้ random forest ในการทำ feature selection จะให้ค่า recall มากที่สุดอยู่ที่ 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองสร้าง Model deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(rf_X_data.shape[1],))\n",
    "x = keras.layers.Dense(32, activation='tanh')(inputs)\n",
    "x = keras.layers.Dense(16, activation='tanh')(x)\n",
    "x = keras.layers.Dense(8, activation='tanh')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองกับข้อมูลที่ทำ feature selection ด้วย Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(rf_X_data).astype('float32')\n",
    "history = model.fit(X_train, rf_y_data, batch_size=16, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(rf_X_test, rf_y_test)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(rf_X_data)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_data, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(rf_X_test)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=rf_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(rf_y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองกับข้อมูลที่ทำ feature selection ด้วย chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(chi2_X_data.shape[1],))\n",
    "x = keras.layers.Dense(32, activation='tanh')(inputs)\n",
    "x = keras.layers.Dense(16, activation='tanh')(x)\n",
    "x = keras.layers.Dense(8, activation='tanh')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(chi2_X_data).astype('float32')\n",
    "history = model.fit(X_train, chi2_y_data, batch_size=16, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(chi2_X_test, chi2_y_test)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(chi2_X_data)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_data, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(chi2_X_test)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=chi2_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(chi2_y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดลองกับข้อมูลที่ทำ feature selection ด้วย PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(pca_X_data.shape[1],))\n",
    "x = keras.layers.Dense(32, activation='tanh')(inputs)\n",
    "x = keras.layers.Dense(16, activation='tanh')(x)\n",
    "x = keras.layers.Dense(8, activation='tanh')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(pca_X_data).astype('float32')\n",
    "history = model.fit(X_train, pca_y_data, batch_size=16, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_scores = model.evaluate(pca_X_test, pca_y_test)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(pca_X_data)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_data, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_data, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of training set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(pca_X_test)\n",
    "y_pred = np.where(y_pred >= 0.5, 1, 0)\n",
    "print(\"Classification report \\n=======================\")\n",
    "print(classification_report(y_true=pca_y_test, y_pred=y_pred))\n",
    "print(\"Confusion matrix \\n=======================\")\n",
    "cm = confusion_matrix(pca_y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title('Confusion matrix of testing set')\n",
    "plt.show()\n",
    "print(\"\\n=======================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยจากการทดลอง Deep Learning กับข้อมูลที่ใช้ feature selection ต่างๆทั้งสามรูปแบบจะเห็นได้ว่าการทำ Deep Learning กับข้อมูลที่ใช้ random forest ในการทำ feature selection จะให้ค่า recall มากที่สุดอยู่ที่ 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "1. จากผลการทดลองพบว่าการทำ feature selection ด้วย PCA จะได้ความแม่นยำที่ต่ำกว่าการทำด้วย Random forest กับ chi2 ในแต่ละโมเดล โดยผลที่เกิดขึ้นเกิดมาจากการที่ PCA ทำการแปลงค่าข้อมูลเดิมให้ไปอยู่ในปริภูมิแบบใหม่ทำให้ลักษณะบางอย่างของข้อมูลมีการสูญหาย\n",
    "2. จากการทดลองใช้ SVM พบว่าได้ผลลัพธ์ที่ค่อนข้างแม่นยำในกรณีที่ใช้ random forest ทำ feature selection เนื่องจากข้อมูลอาจสามารถแปลงไปในปริภูมิใหม่โดยใช้ kernel method ของ SVM แล้วใช้ hyperplane แบ่งได้\n",
    "3. จากการทดลองโมเดล Random Forest กับข้อมูลที่ใช้ Feature Selection ทั้งสามรูปแบบให้ผล recall โดยรวมออกมาดีที่สุด\n",
    "4. จากการทดลองโมเดล กับข้อมูลที่ใช้ Random Forest ในการทำ Feature Selection ให้ผล recall โดยรวมกับโมเดลทั้ง 6 ดีที่สุด ดังนั้นหากมีความต้องการจะ predict ลูกค้าที่จะเลิกบัตรเครดิตไม่ให้ผิดพลาดมาก โมเดลที่ train มายังเหมาะสมที่จะนำไปใช้"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929163599431c7b3e753eb9c75a6800fa8c5c72fb3910ee126ea89c879162a29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
